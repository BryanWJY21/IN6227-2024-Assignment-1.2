# Importing necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, classification_report
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
import time

# Load the dataset
columns = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 
           'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 
           'hours_per_week', 'native_country', 'income']

train_data = pd.read_csv('adult.data', names=columns, sep=',\s', engine='python')
test_data = pd.read_csv('adult.test', names=columns, sep=',\s', engine='python', skiprows=1)

# Preprocessing: Handle missing values, duplicates, and encode categorical features

# Replace '?' with NaN (missing values)
train_data = train_data.replace('?', pd.NA)
test_data = test_data.replace('?', pd.NA)

# Remove duplicate rows
train_data = train_data.drop_duplicates()
test_data = test_data.drop_duplicates()

# Impute missing values using mode for categorical columns
for column in train_data.columns:
    if train_data[column].dtype == 'object':
        train_data[column].fillna(train_data[column].mode()[0], inplace=True)
        test_data[column].fillna(test_data[column].mode()[0], inplace=True)

# Encode categorical features
label_encoders = {}
for column in train_data.select_dtypes(include=['object']).columns:
    label_encoders[column] = LabelEncoder()
    train_data[column] = label_encoders[column].fit_transform(train_data[column])
    
    # Clean labels in test data (remove periods from the income column)
    if column == 'income':
        test_data[column] = test_data[column].str.strip('.')
    
    test_data[column] = label_encoders[column].transform(test_data[column])

# Split the data into features (X) and labels (y)
X_train = train_data.drop('income', axis=1)
y_train = train_data['income']
X_test = test_data.drop('income', axis=1)
y_test = test_data['income']

# Model 1: K-Nearest Neighbors (KNN) with Hyperparameter Tuning

# Define the hyperparameter grid for KNN
param_grid_knn = {
    'n_neighbors': [3, 5, 7, 9],      # Trying different K values
    'weights': ['uniform', 'distance'],
    'metric': ['euclidean', 'manhattan', 'minkowski']
}

# Create a KNN model
knn_model = KNeighborsClassifier()

# Perform Grid Search with cross-validation
grid_search_knn = GridSearchCV(estimator=knn_model, param_grid=param_grid_knn, cv=5, scoring='accuracy')
start_time = time.time()
grid_search_knn.fit(X_train, y_train)
knn_train_time = time.time() - start_time

# Get the best parameters for KNN
print("Best KNN parameters: ", grid_search_knn.best_params_)

# Use the best KNN model
best_knn_model = grid_search_knn.best_estimator_

# Predict and evaluate KNN
start_time = time.time()
y_pred_best_knn = best_knn_model.predict(X_test)
knn_test_time = time.time() - start_time
accuracy_best_knn = accuracy_score(y_test, y_pred_best_knn)
report_knn = classification_report(y_test, y_pred_best_knn)

print(f"Best KNN accuracy: {accuracy_best_knn}")
print("Classification Report for KNN:\n", report_knn)
print(f"KNN Training Time: {knn_train_time}")
print(f"KNN Testing Time: {knn_test_time}")

# Model 2: Decision Tree Classifier with Hyperparameter Tuning

# Define the hyperparameter grid for Decision Tree
param_grid_dt = {
    'max_depth': [3, 5, 7, 10, None],       # Tree depth
    'min_samples_split': [2, 10, 20],       # Minimum samples required to split a node
    'min_samples_leaf': [1, 5, 10],         # Minimum samples in a leaf node
    'criterion': ['gini', 'entropy']        # Splitting criterion
}

# Create a Decision Tree model
dt_model = DecisionTreeClassifier()

# Perform Grid Search with cross-validation
grid_search_dt = GridSearchCV(estimator=dt_model, param_grid=param_grid_dt, cv=5, scoring='accuracy')
start_time = time.time()
grid_search_dt.fit(X_train, y_train)
dt_train_time = time.time() - start_time

# Get the best parameters for Decision Tree
print("Best Decision Tree parameters: ", grid_search_dt.best_params_)

# Use the best Decision Tree model
best_dt_model = grid_search_dt.best_estimator_

# Predict and evaluate Decision Tree
start_time = time.time()
y_pred_best_dt = best_dt_model.predict(X_test)
dt_test_time = time.time() - start_time
accuracy_best_dt = accuracy_score(y_test, y_pred_best_dt)
report_dt = classification_report(y_test, y_pred_best_dt)

print(f"Best Decision Tree accuracy: {accuracy_best_dt}")
print("Classification Report for Decision Tree:\n", report_dt)
print(f"Decision Tree Training Time: {dt_train_time}")
print(f"Decision Tree Testing Time: {dt_test_time}")

# Summary of the comparison
print("\nSummary of Model Comparison:")
print(f"KNN - Accuracy: {accuracy_best_knn}, Train Time: {knn_train_time}, Test Time: {knn_test_time}")
print(f"Decision Tree - Accuracy: {accuracy_best_dt}, Train Time: {dt_train_time}, Test Time: {dt_test_time}")
